<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>Hadoop Job Executor 2 adv</name>
  <description/>
  <extended_description/>
  <job_version/>
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2010/07/12 13:45:27.737</created_date>
  <modified_user>-</modified_user>
  <modified_date>2010/07/12 13:45:27.737</modified_date>
  <parameters>
    </parameters>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection/>
    <schema/>
    <table/>
    <size_limit_lines/>
    <interval/>
    <timeout_days/>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <checkpoint-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <max_nr_retries/>
    <run_retry_period/>
    <namespace_parameter/>
    <save_parameters/>
    <save_result_rows/>
    <save_result_files/>
    <field>
      <id>ID_JOB_RUN</id>
      <enabled>Y</enabled>
      <name>ID_JOB_RUN</name>
    </field>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>NAMESPACE</id>
      <enabled>Y</enabled>
      <name>NAMESPACE</name>
    </field>
    <field>
      <id>CHECKPOINT_NAME</id>
      <enabled>Y</enabled>
      <name>CHECKPOINT_NAME</name>
    </field>
    <field>
      <id>CHECKPOINT_COPYNR</id>
      <enabled>Y</enabled>
      <name>CHECKPOINT_COPYNR</name>
    </field>
    <field>
      <id>ATTEMPT_NR</id>
      <enabled>Y</enabled>
      <name>ATTEMPT_NR</name>
    </field>
    <field>
      <id>JOB_RUN_START_DATE</id>
      <enabled>Y</enabled>
      <name>JOB_RUN_START_DATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>RESULT_XML</id>
      <enabled>Y</enabled>
      <name>RESULT_XML</name>
    </field>
    <field>
      <id>PARAMETER_XML</id>
      <enabled>Y</enabled>
      <name>PARAMETER_XML</name>
    </field>
  </checkpoint-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>WordCount - Advanced</name>
      <description/>
      <type>HadoopJobExecutorPlugin</type>
      <hadoop_job_name>hadoopjob - wordcount2</hadoop_job_name>
      <simple>N</simple>
      <jar_url>./samples/jobs/hadoop/pentaho-mapreduce2-sample.jar</jar_url>
      <driver_class>org.pentaho.hadoop.sample.wordcount.WordCount2</driver_class>
      <command_line_args>/wordcount/input /wordcount/output</command_line_args>
      <simple_blocking>N</simple_blocking>
      <blocking>Y</blocking>
      <logging_interval>5</logging_interval>
      <simple_logging_interval>60</simple_logging_interval>
      <hadoop_job_name>hadoopjob - wordcount2</hadoop_job_name>
      <mapper_class>org.pentaho.hadoop.sample.wordcount.WordCount2$Map</mapper_class>
      <combiner_class>org.pentaho.hadoop.sample.wordcount.WordCount2$Reduce</combiner_class>
      <reducer_class>org.pentaho.hadoop.sample.wordcount.WordCount2$Reduce</reducer_class>
      <input_path>/wordcount/input</input_path>
      <input_format_class>org.apache.hadoop.mapreduce.lib.input.TextInputFormat</input_format_class>
      <output_path>/wordcount/output</output_path>
      <output_key_class>org.apache.hadoop.io.Text</output_key_class>
      <output_value_class>org.apache.hadoop.io.IntWritable</output_value_class>
      <output_format_class>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</output_format_class>
      <hdfs_hostname>localhost</hdfs_hostname>
      <hdfs_port>8020</hdfs_port>
      <job_tracker_hostname>localhost</job_tracker_hostname>
      <job_tracker_port>8032</job_tracker_port>
      <num_map_tasks>2</num_map_tasks>
      <num_reduce_tasks>1</num_reduce_tasks>
      <user_defined_list>
      </user_defined_list>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>478</xloc>
      <yloc>290</yloc>
    </entry>
    <entry>
      <name>START</name>
      <description/>
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>56</xloc>
      <yloc>290</yloc>
    </entry>
    <entry>
      <name>Clean Output</name>
      <description/>
      <type>DELETE_FOLDERS</type>
      <arg_from_previous>N</arg_from_previous>
      <success_condition>success_if_no_errors</success_condition>
      <limit_folders>10</limit_folders>
      <fields>
        <field>
          <name>hdfs://hadoop-server:8020/wordcount/output</name>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>252</xloc>
      <yloc>290</yloc>
    </entry>
    <entry>
      <name>Success</name>
      <description/>
      <type>SUCCESS</type>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>678</xloc>
      <yloc>290</yloc>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>START</from>
      <to>Clean Output</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Clean Output</from>
      <to>WordCount - Advanced</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>WordCount - Advanced</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>Cleans up the output directory</note>
      <xloc>191</xloc>
      <yloc>236</yloc>
      <width>183</width>
      <heigth>23</heigth>
      <fontname>Microsoft Sans Serif</fontname>
      <fontsize>8</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Hadoop WordCount MapReduce Job
- Edit the Input and Output directory paths
- Choose Hadoop Cluster</note>
      <xloc>399</xloc>
      <yloc>353</yloc>
      <width>250</width>
      <heigth>49</heigth>
      <fontname>Microsoft Sans Serif</fontname>
      <fontsize>8</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Monitor the logs for progress
(if blocking option is selected)</note>
      <xloc>610</xloc>
      <yloc>222</yloc>
      <width>178</width>
      <heigth>36</heigth>
      <fontname>Microsoft Sans Serif</fontname>
      <fontsize>8</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>SETUP INSTRUCTIONS:
1. Update the HDFS path within the 'Clean Output' step to match your Hadoop server location and path to where you intend to generate output from the wordcount example
2. Create an input directory in HDFS and place text file(s) in the input directory that you want to use to test the wordcount example
3. Update the 'Wordcount - Advanced' step (Job Setup and Cluster tabs) to configure the correct paths and server name including:
    - Input Path - the path in HDFS from which to read files for counting
    - Output Path - where the processed count of words will be placed

*Note: Source code for the sample jar can be found alongside this sample in your samples directory.</note>
      <xloc>15</xloc>
      <yloc>26</yloc>
      <width>991</width>
      <heigth>114</heigth>
      <fontname>Microsoft Sans Serif</fontname>
      <fontsize>8</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>165</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>JobRestart</name>
      <attribute>
        <key>UniqueConnections</key>
        <value>N</value>
      </attribute>
    </group>
  </attributes>
</job>
